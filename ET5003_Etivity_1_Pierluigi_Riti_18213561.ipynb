{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET5003_Etivity_1_Pierluigi_Riti_18213561.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxK1_8f1dvrc"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_Etivity-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-09-08' #@param {type:\"date\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO",
        "cellView": "form"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Student_ID = \"18213561\" #@param {type:\"string\"}\n",
        "Student_full_name = \"Pierluigi Riti\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx",
        "cellView": "form"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Etivity' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80m304lUefG4"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs8mHGcidHSa"
      },
      "source": [
        "\n",
        "\n",
        "The MNIST database  is a dataset of handwritten digits that has been and is extensively used in machine learning. There are $10$ classes, each image is $28\\times28$ pixels and, therefore, each input is $x_i\\in\\mathbb{R}^{784}$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailycCq5epj2"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-yNAxhUemjM"
      },
      "source": [
        "You have to extend the code to manage any arbitrary number of classes, in other words you have to implement a general-recipe multinomial logistic classifier and Bayesian multinomial logistic classifier.\n",
        "\n",
        "You must then select  3 digits at random and perform  the following task. \n",
        "\n",
        "1. Your goal is to use Bayesian multinomial logistic regression (as in the road-sign notebook) to solve this classification problem. \n",
        "\n",
        "2. You can downsize the training dataset (e.g., 40% training and 60%testing) if the computation of the posterior takes too much time in your computer.\n",
        "\n",
        "3. Use the posterior uncertainty to detect the instances (digits) in the test set that are hard to classify and remove them from the test-set.\n",
        "\n",
        "4. Then you need to compute again the accuracy of the general-recipe logistic regression on the remaining (non-difficult) instances and comment on the result.\n",
        "\n",
        "5. In practice, the task is to use uncertainty estimation to detect the difficult instances in the test-set. This is equivalent to refuse to classify all high-uncertainty instances or, in other words, when we are uncertain we say \"I don't know\" and we do not return any class. In this way, you will learn how uncertainty can be used to make safer decisions, by detecting the instances that are difficult to classify.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMRKRTQZe5fW"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxusAui7AX_f"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQOfGMQpdHSb"
      },
      "source": [
        "# Import libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.optimize as optimize\n",
        "from scipy.special import erf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import arviz as az\n",
        "from scipy.io import loadmat\n",
        "import pymc3 as pm\n",
        "import random\n",
        "from IPython.display import HTML\n",
        "import pickle\n",
        "import theano as tt\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-qMSjpAQ-9"
      },
      "source": [
        "# Setting a seed:\n",
        "np.random.seed(123)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4hSuwkUfVQb"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w99Pc66YdHSd"
      },
      "source": [
        "### Loading the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYFWAbXVzynp",
        "outputId": "c52b145f-10da-4cc8-a24e-99ba0cdca4d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rCnS4vdHSd",
        "outputId": "06b4f6e4-9efb-478b-b666-663e512fdf5a"
      },
      "source": [
        "# Path, copy the path from your Drive\n",
        "Path = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "# MNIST Data\n",
        "train_data = Path + 'mnist_train.csv'\n",
        "test_data = Path + 'mnist_test.csv'\n",
        "\n",
        "# train data\n",
        "df_train = pd.read_csv(train_data)\n",
        "X_train = df_train.drop(\"label\",axis=1).values\n",
        "y_train = df_train.label.values\n",
        "print(X_train.shape)\n",
        "\n",
        "# test data\n",
        "df_test = pd.read_csv(test_data)\n",
        "X_test = df_test.drop(\"label\",axis=1).values\n",
        "y_test = df_test.label.values\n",
        "print(X_test.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2ubJ_WoAqBh",
        "outputId": "cf44f8b0-a070-4c63-e241-d7474a5dc0db"
      },
      "source": [
        "# Normalizing the Inputs:\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "# Printing the new input range of values:\n",
        "minv = np.min(X_train)\n",
        "maxv = np.max(X_train)\n",
        "print(minv,maxv)\n",
        "print(len(X_train))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n",
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e636WoglOZ_6"
      },
      "source": [
        "# **Preprocessing Data Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zRTkQSlOidE"
      },
      "source": [
        "### Preprocess the data here. \n",
        "## Preprocessing steps could include normalization, converting to grayscale, etc.\n",
        "\n",
        "def normalize(img):\n",
        "    return cv2.normalize(img, img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    \n",
        "\n",
        "def grayscale(img):\n",
        "    #COLOR_BGR2GRAY COLOR_RGB2GRAY\n",
        "    return rgb2gray(img)\n",
        "    #return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  \n",
        "\n",
        "def setgrayscale(images):\n",
        "    #from rgb to gray\n",
        "    print(images.shape)\n",
        "    result = np.zeros(shape=(len(images),28,28))\n",
        "    for i in range(len(images)): \n",
        "        gray_img = grayscale(images[i])\n",
        "        img_normalized = normalize(gray_img)\n",
        "        result[i] = gray_img\n",
        "    print(result.shape)\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR6HpkWndHSe"
      },
      "source": [
        "### Description of Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sibN1Vv1dHSf",
        "outputId": "5e9fbcfb-815b-4178-dcf5-dfc87ec9525e"
      },
      "source": [
        "# Number of examples\n",
        "n_train =  len(X_train)\n",
        "n_test =  len(X_test)\n",
        "\n",
        "# Shape of an traffic sign image\n",
        "image_shape = X_train.shape[1]\n",
        "\n",
        "# unique classes/labels in the training dataset.\n",
        "alltotal = set(y_train)\n",
        "n_classes = len(alltotal)\n",
        "\n",
        "print(\"Number of Training examples =\", n_train)\n",
        "print(\"Number of Test examples =\", n_test)\n",
        "print(\"Image input shape =\", image_shape)\n",
        "print(\"Number of classes =\", n_classes)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training examples = 60000\n",
            "Number of Test examples = 10000\n",
            "Image input shape = 784\n",
            "Number of classes = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HQDSvrRKZF6"
      },
      "source": [
        "### Class Distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8GdlpBKdCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7d5d16db-d9a8-4202-a5b7-747dd085a28f"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ind = np.arange(n_classes)\n",
        "\n",
        "n, bins, patches = ax.hist(y_train, n_classes)\n",
        "ax.set_xlabel('classes')\n",
        "ax.set_ylabel('counts')\n",
        "ax.set_title(r'Histogram of Digit images')\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyLWw3nsLCtk"
      },
      "source": [
        "## Downsampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U1lFEwhLKBf"
      },
      "source": [
        "### Randomly selecting 3 of the 10 Digit Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EeRZZWdLRPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2acf2e-af74-407e-f2bc-c4762db89937"
      },
      "source": [
        "# We select the number of Classes we want:\n",
        "n_classes = 3\n",
        "\n",
        "# Empty list to append the random digit classes we select:\n",
        "classes = []\n",
        "\n",
        "print(alltotal)\n",
        "\n",
        "# We select 3 digits at random and make sure they are unique:\n",
        "# the alltotal is the total number of the class in the dataset\n",
        "while len(classes) < n_classes:\n",
        "    \n",
        "    # Randomly drawing a digit from 0-9:\n",
        "    num2choose = np.random.randint(0,10)\n",
        "\n",
        "    # Append the digit if it's not already in our list of classes:\n",
        "    if num2choose not in classes: \n",
        "        classes.append(num2choose)\n",
        "        \n",
        "        \n",
        "# Sorting the Classes smallest to largest    \n",
        "classes.sort()\n",
        "# print classes selected\n",
        "classes"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M8R5NqKMB_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a654cfa2-ebbd-462f-8b9c-e280ca58947c"
      },
      "source": [
        "# The number of instances we'll keep for each of our 3 digits:\n",
        "inst_class = 500\n",
        "\n",
        "inputs = []\n",
        "labels = []\n",
        "\n",
        "# Loop to randomly sample the instances for each digit:\n",
        "for r in classes:\n",
        "    imgs = X_train[np.where(y_train==r)[0],:]\n",
        "    inputs.append(imgs[np.random.permutation(imgs.shape[0]),:][0:inst_class,:])\n",
        "    labels.append(np.ones(inst_class)*r)\n",
        "    \n",
        "# Shaping inputs and labels in the right format    \n",
        "X_train = np.vstack(inputs).astype(np.float64)\n",
        "y_train = np.hstack(labels)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 784)\n",
            "(1500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6-YHrQQMicy"
      },
      "source": [
        "New Classes Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFgP4xugMvJm"
      },
      "source": [
        "# plot digits\n",
        "def plot_digits(instances, images_per_row=5, **options):\n",
        "    size = 28\n",
        "    images_per_row = min(len(instances), images_per_row)\n",
        "    images = [instance.reshape(size,size) for instance in instances]\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    row_images = []\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    images.append(np.zeros((size, size * n_empty)))\n",
        "    for row in range(n_rows):\n",
        "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
        "        row_images.append(np.concatenate(rimages, axis=1))\n",
        "    image = np.concatenate(row_images, axis=0)\n",
        "    plt.imshow(image,  cmap='gist_yarg', **options)\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeEG-LGOM4fJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea197655-3765-4081-b63d-daf448236b43"
      },
      "source": [
        "# Show a few instances from each Digit:\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "print(classes)\n",
        "\n",
        "label_indices = []\n",
        "# Selecting a few label indices from each of the 3 classes to show:\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    # take index randomly chosen\n",
        "    label_indices.append(random.randint(0, len(classes)))\n",
        "    print(classes[i])\n",
        "    # choose the image according to the index\n",
        "    image = X_train[classes[i] - 1]\n",
        "    print(image)\n",
        "\n",
        "# Plotting 'original' image\n",
        "plot_digits(X_train[classes],images_per_row=5)\n",
        "plt.title(\"Original Digits\", fontsize=14)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 6]\n",
            "1\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.07058824\n",
            " 0.79215686 0.17647059 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.23137255 0.99607843 0.59215686\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.23137255 0.99607843 0.8745098  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.23137255\n",
            " 0.99607843 0.8745098  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.23137255 0.99607843 0.8745098\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.23137255 0.99607843 0.8745098  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.23137255\n",
            " 0.99607843 0.8745098  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.23137255 0.99607843 0.8745098\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.55686275 0.99607843 0.8745098  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.51764706\n",
            " 0.99607843 0.56470588 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.2745098  0.99607843 0.52156863\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.58039216 0.99607843 0.79607843 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.45098039\n",
            " 0.99607843 0.8745098  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.23137255 0.99607843 0.8745098\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.3254902  0.99607843 0.8745098  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.58039216\n",
            " 0.99607843 0.8745098  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.58039216 0.99607843 0.81568627\n",
            " 0.11764706 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.58039216 0.99607843 0.89803922 0.04313725 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.58039216\n",
            " 0.99607843 0.85490196 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.45882353 0.9372549  0.21960784\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "2\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.71372549 1.         0.58431373 0.24313725 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.70588235 0.99215686\n",
            " 0.98431373 0.84313725 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.74509804 0.99215686 0.98431373 0.8627451\n",
            " 0.08235294 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.42745098\n",
            " 0.98431373 0.99215686 0.98431373 0.92156863 0.32156863 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.42745098 0.98431373 0.99215686\n",
            " 0.98431373 0.84313725 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14509804 0.99215686 0.99215686 1.         0.99215686 0.64313725\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14509804 0.98431373\n",
            " 0.98431373 0.99215686 0.98431373 0.1372549  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.14509804 0.98431373 0.98431373 0.99215686\n",
            " 0.98431373 0.1372549  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14509804 0.98431373 0.98431373 0.99215686 0.98431373 0.1372549\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.65098039 0.98431373\n",
            " 0.98431373 0.99215686 0.57647059 0.03921569 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.85490196 0.99215686 0.99215686 1.\n",
            " 0.42352941 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.85098039 0.98431373 0.98431373 0.99215686 0.41960784 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.85098039 0.98431373\n",
            " 0.98431373 0.99215686 0.41960784 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.85098039 0.98431373 0.98431373 0.99215686\n",
            " 0.41960784 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.85098039 0.98431373 0.98431373 0.99215686 0.41960784 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.56862745 0.99215686 0.99215686\n",
            " 0.99215686 0.71372549 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.56470588 0.98431373 0.98431373 0.98431373 0.87058824\n",
            " 0.24313725 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.56470588\n",
            " 0.98431373 0.98431373 0.98431373 0.94901961 0.36078431 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.56470588 0.98431373 0.98431373\n",
            " 0.98431373 0.70588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.16078431 0.88627451 0.98431373 0.47843137 0.2\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "6\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.89411765 1.         0.89411765\n",
            " 0.16078431 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4        0.98431373 0.99215686 0.99215686 0.34901961 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.43529412 0.99215686\n",
            " 0.99215686 0.99215686 0.34901961 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.43529412 0.99215686 0.99215686 0.95294118\n",
            " 0.2745098  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.43529412 0.99215686 0.99215686 0.80392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.75294118 0.99215686\n",
            " 0.99215686 0.80392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.97254902 0.99215686 0.99215686 0.80392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.97254902 0.99215686 0.99215686 0.80392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.97254902 0.99215686\n",
            " 0.99215686 0.80392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.97254902 0.99215686 0.99215686 0.80392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.97254902 0.99215686 0.99215686 0.80392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.97254902 0.99215686\n",
            " 0.99215686 0.80392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.97254902 0.99215686 0.99215686 0.80392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.97254902 0.99215686 0.99215686 0.80392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.4627451  0.99215686\n",
            " 0.99215686 0.80392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.43529412 0.99215686 0.99215686 0.86666667\n",
            " 0.11372549 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.32941176 0.96862745 0.99215686 0.99215686 0.47843137 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.50980392\n",
            " 0.99215686 0.99215686 0.90196078 0.07058824 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.13333333 0.81176471 0.97254902\n",
            " 0.9254902  0.16078431 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.72941176 0.88627451 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Original Digits')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsAOnOcNNG_V"
      },
      "source": [
        "###  Splitting the Training data into both Training and Validation Sets:\n",
        "\n",
        "- Although this is the Training set, we can still set aside some samples (for instance 20%) of the 1,500 instances we have for Model Validation purposes.\n",
        "\n",
        "\n",
        "- With that Validation Set, we can then select the amount of Uncertainty we are happy with from our Model to use out of sample on other unseen data.\n",
        "\n",
        "\n",
        "- We can then test out how well our decision performs on the Test Set that we put aside earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdsmyVAtPXNn"
      },
      "source": [
        "### Split tha dataset in training and validation sets\n",
        "# choose the fraction of your validation data from the training set\n",
        "w = 0.20\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=w, random_state=0)\n",
        " \n",
        "# Shuffling the training instaces around to randomize the order of inputs to the model:\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXwJwP0iPxhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3340f26a-d1de-449b-8aa3-43b73bda7554"
      },
      "source": [
        "# print shape of your validation and training set\n",
        "print(X_train.shape)\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOroY1QoP8DY"
      },
      "source": [
        "### Encoding the Class labels for the Probabilistic ML Model:\n",
        "\n",
        "This is an example:\n",
        "\n",
        "- **[1,0,0]** for first digit\n",
        "- **[0,1,0]** for second digit\n",
        "- **[0,0,1]** for third digit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjUaqWTqQIcp"
      },
      "source": [
        "### General-Recipe ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzgdivxfQNv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01968bd-88cb-44b1-aebf-e7de7e45efbb"
      },
      "source": [
        "# model\n",
        "model_log = LogisticRegression(random_state=0, \n",
        "                               max_iter=2000, C=100, \n",
        "                               solver='lbfgs', \n",
        "                               multi_class='multinomial').fit(X_train, y_train)\n",
        "\n",
        "# Classification:\n",
        "y_pred_log = model_log.predict(X_val)\n",
        "y_pred_logi_prob = model_log.predict_proba(X_val)\n",
        "\n",
        "# Maybe taking the maximum probability \n",
        "# in any of the classes for each observation\n",
        "\n",
        "\n",
        "# Computing the Accuracy:\n",
        "accuracy_score(y_pred_log, y_val)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uQG6JsOQxH5"
      },
      "source": [
        "### Probabilistic Multinomial Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3jzczJzRAtT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irlmUNw7Q5YL"
      },
      "source": [
        "The Multinomial Logistic Regression has some parameters:\n",
        "\n",
        "- $\\alpha$, which is the intercept term:\n",
        "\n",
        "- $\\beta$, which is a vector of coefficients which give a weighting to the importance of each input feature:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o7mbKWmRhz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj6Uzc05Rhtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MFH4gwlRhrB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmJvYc4Rho7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXh5GXJsRhmr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcshsLOGRPrk"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTc4pYKGRR60"
      },
      "source": [
        "Populate this section with all of your findings and comments fron the discussion with your peers."
      ]
    }
  ]
}